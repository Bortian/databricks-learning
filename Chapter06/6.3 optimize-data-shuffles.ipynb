{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d05d7a1-fe97-491a-a177-c1886a5f8baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession \n",
    "from pyspark.sql.functions import * \n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bfbe105-2fd1-43f1-95e9-525d85226a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/09/23 11:21:35 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# Create a new SparkSession\n",
    "spark = (SparkSession\n",
    "         .builder\n",
    "         .appName(\"optimize-data-shuffles\")\n",
    "         .master(\"spark://spark-master:7077\")\n",
    "         .config(\"spark.executor.memory\", \"512m\")\n",
    "         .getOrCreate())\n",
    "\n",
    "# Set log level to ERROR\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2ae2e1f7-45c3-486a-970e-0727eb303197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---+------+------+-----+\n",
      "| id|      date|age|salary|gender|grade|\n",
      "+---+----------+---+------+------+-----+\n",
      "|  0|2022-12-01| 77|  9600|     F|   IC|\n",
      "|  1|2023-08-17| 51|  7500|     F|   M3|\n",
      "|  2|2023-02-10| 58|  6700|     M|   IC|\n",
      "|  3|2023-05-08| 21|  7300|     M|   M2|\n",
      "|  4|2023-01-14| 34|  5500|     M|   M3|\n",
      "+---+----------+---+------+------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create some sample data frames\n",
    "# A large data frame with 1 million rows and two columns: id and value\n",
    "large_df = (spark.range(0, 1000000)\n",
    "            .withColumn(\"date\", date_sub(current_date(), (rand() * 365).cast(\"int\")))\n",
    "            .withColumn(\"age\", (rand() * 100).cast(\"int\"))\n",
    "            .withColumn(\"salary\", 100*(rand() * 100).cast(\"int\"))\n",
    "            .withColumn(\"gender\", when((rand() * 2).cast(\"int\") == 0, \"M\").otherwise(\"F\"))\n",
    "            .withColumn(\"grade\", \n",
    "                        when((rand() * 5).cast(\"int\") == 0, \"IC\")\n",
    "                        .when((rand() * 5).cast(\"int\") == 1, \"IC-2\")\n",
    "                        .when((rand() * 5).cast(\"int\") == 2, \"M1\")\n",
    "                        .when((rand() * 5).cast(\"int\") == 3, \"M2\")\n",
    "                        .when((rand() * 5).cast(\"int\") == 4, \"IC-3\")\n",
    "                        .otherwise(\"M3\")))\n",
    "large_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5e1b2f38-375a-4c39-94ab-45597162caf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------------+\n",
      "|age|       avg(bonus)|\n",
      "+---+-----------------+\n",
      "| 85|5433.093191540399|\n",
      "| 65|5425.068434303069|\n",
      "| 78|5433.110714750945|\n",
      "| 81|5443.704115016358|\n",
      "| 76|  5445.9012274569|\n",
      "+---+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, avg\n",
    "\n",
    "# Filter the DataFrame by gender\n",
    "df_filtered = large_df.filter(col(\"age\") >= 55)\n",
    "\n",
    "# Map the DataFrame by adding 10% bonus to salary\n",
    "df_mapped = df_filtered.withColumn(\"bonus\", col(\"salary\") * 1.1)\n",
    "\n",
    "# Locally aggregate the DataFrame by computing the average bonus by age\n",
    "df_aggregated = df_mapped.groupBy(\"age\").agg(avg(\"bonus\"))\n",
    "\n",
    "# Print the result\n",
    "df_aggregated.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d2492f49-744d-44ea-a253-1b73c1d04710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- HashAggregate(keys=[age#542], functions=[avg(bonus#589)])\n",
      "   +- Exchange hashpartitioning(age#542, 200), ENSURE_REQUIREMENTS, [plan_id=1003]\n",
      "      +- HashAggregate(keys=[age#542], functions=[partial_avg(bonus#589)])\n",
      "         +- Project [age#542, (cast(salary#546 as double) * 1.1) AS bonus#589]\n",
      "            +- Filter (isnotnull(age#542) AND (age#542 >= 55))\n",
      "               +- Project [age#542, (cast((rand(-2852223682338606353) * 100.0) as int) * 100) AS salary#546]\n",
      "                  +- Project [cast((rand(-24633094416071200) * 100.0) as int) AS age#542]\n",
      "                     +- Range (0, 10000000, step=1, splits=2)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_aggregated.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "480aba43-0e1d-4f84-82e0-c7cdaa9debb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------------+\n",
      "|level|       avg(salary)|\n",
      "+-----+------------------+\n",
      "|    F| 4948.528276926469|\n",
      "|    E| 4948.176937814321|\n",
      "|    B| 4943.605257876781|\n",
      "|    D|4957.5704561678685|\n",
      "|    C| 4931.937575557754|\n",
      "|    J| 4934.395221008479|\n",
      "|    A|4958.7079856021855|\n",
      "|    G| 4973.518919352253|\n",
      "|    I| 4931.880394820972|\n",
      "|    H| 4951.178290409542|\n",
      "+-----+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import broadcast\n",
    "\n",
    "# Create another DataFrame with some dummy data\n",
    "df2 = spark.createDataFrame([(25, \"A\"), (30, \"B\"), (35, \"C\"), (40, \"D\"), (45, \"E\"), (50, \"F\"), (55, \"G\"), (60, \"H\"), (65, \"I\"), (70, \"J\")], [\"age\", \"level\"])\n",
    "\n",
    "# Join the two DataFrames by age using broadcast join\n",
    "df_joined = large_df.join(broadcast(df2), \"age\")\n",
    "\n",
    "# Globally aggregate the joined DataFrame by computing the sum of salary by level using partial aggregation\n",
    "df_aggregated = df_joined.groupBy(\"level\").avg(\"salary\")\n",
    "\n",
    "# Print the result\n",
    "df_aggregated.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1bc13c8b-a1fc-41b1-b0b2-06f00ff5e7db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- HashAggregate(keys=[level#624], functions=[avg(salary#546)])\n",
      "   +- Exchange hashpartitioning(level#624, 200), ENSURE_REQUIREMENTS, [plan_id=1191]\n",
      "      +- HashAggregate(keys=[level#624], functions=[partial_avg(salary#546)])\n",
      "         +- Project [salary#546, level#624]\n",
      "            +- BroadcastHashJoin [cast(age#542 as bigint)], [age#623L], Inner, BuildRight, false\n",
      "               :- Filter isnotnull(age#542)\n",
      "               :  +- Project [age#542, (cast((rand(-2852223682338606353) * 100.0) as int) * 100) AS salary#546]\n",
      "               :     +- Project [cast((rand(-24633094416071200) * 100.0) as int) AS age#542]\n",
      "               :        +- Range (0, 10000000, step=1, splits=2)\n",
      "               +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, bigint, false]),false), [plan_id=1186]\n",
      "                  +- Filter isnotnull(age#623L)\n",
      "                     +- Scan ExistingRDD[age#623L,level#624]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_aggregated.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dbf4ad27-0f23-4304-8b99-cf34408e3b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 36:>                                                         (0 + 2) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 38:>                                                         (0 + 2) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Repartition the DataFrame by gender with 2 partitions\n",
    "df_repartitioned = large_df.repartition(col(\"gender\"))\n",
    "\n",
    "# Repartition the DataFrame by age range with 5 partitions\n",
    "df_repartitioned_by_range = large_df.repartitionByRange(5, col(\"age\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3cf5ea6f-0ef3-4938-ac60-140b857e051e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(1) Project [id#537L, date#539, age#542, salary#546, gender#551, CASE WHEN (cast((rand(7627123849445037294) * 5.0) as int) = 0) THEN IC WHEN (cast((rand(-3606855761943417541) * 5.0) as int) = 1) THEN IC-2 WHEN (cast((rand(2762691268524896822) * 5.0) as int) = 2) THEN M1 WHEN (cast((rand(-8349312454092533537) * 5.0) as int) = 3) THEN M2 WHEN (cast((rand(4327064802130063657) * 5.0) as int) = 4) THEN IC-3 ELSE M3 END AS grade#557]\n",
      "+- *(1) Project [id#537L, date#539, age#542, salary#546, CASE WHEN (cast((rand(-1048537541828757866) * 2.0) as int) = 0) THEN M ELSE F END AS gender#551]\n",
      "   +- *(1) Project [id#537L, date#539, age#542, (cast((rand(-2852223682338606353) * 100.0) as int) * 100) AS salary#546]\n",
      "      +- *(1) Project [id#537L, date#539, cast((rand(-24633094416071200) * 100.0) as int) AS age#542]\n",
      "         +- *(1) Project [id#537L, date_sub(2023-09-23, cast((rand(-4631883687744543562) * 365.0) as int)) AS date#539]\n",
      "            +- *(1) Range (0, 10000000, step=1, splits=2)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "large_df.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4327c59e-007c-4b64-b9a3-d6f800d0ad97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=true\n",
      "+- == Final Plan ==\n",
      "   AQEShuffleRead coalesced\n",
      "   +- ShuffleQueryStage 0\n",
      "      +- Exchange hashpartitioning(gender#551, 200), REPARTITION_BY_COL, [plan_id=1259]\n",
      "         +- *(1) Project [id#537L, date#539, age#542, salary#546, gender#551, CASE WHEN (cast((rand(7627123849445037294) * 5.0) as int) = 0) THEN IC WHEN (cast((rand(-3606855761943417541) * 5.0) as int) = 1) THEN IC-2 WHEN (cast((rand(2762691268524896822) * 5.0) as int) = 2) THEN M1 WHEN (cast((rand(-8349312454092533537) * 5.0) as int) = 3) THEN M2 WHEN (cast((rand(4327064802130063657) * 5.0) as int) = 4) THEN IC-3 ELSE M3 END AS grade#557]\n",
      "            +- *(1) Project [id#537L, date#539, age#542, salary#546, CASE WHEN (cast((rand(-1048537541828757866) * 2.0) as int) = 0) THEN M ELSE F END AS gender#551]\n",
      "               +- *(1) Project [id#537L, date#539, age#542, (cast((rand(-2852223682338606353) * 100.0) as int) * 100) AS salary#546]\n",
      "                  +- *(1) Project [id#537L, date#539, cast((rand(-24633094416071200) * 100.0) as int) AS age#542]\n",
      "                     +- *(1) Project [id#537L, date_sub(2023-09-23, cast((rand(-4631883687744543562) * 365.0) as int)) AS date#539]\n",
      "                        +- *(1) Range (0, 10000000, step=1, splits=2)\n",
      "+- == Initial Plan ==\n",
      "   Exchange hashpartitioning(gender#551, 200), REPARTITION_BY_COL, [plan_id=1243]\n",
      "   +- Project [id#537L, date#539, age#542, salary#546, gender#551, CASE WHEN (cast((rand(7627123849445037294) * 5.0) as int) = 0) THEN IC WHEN (cast((rand(-3606855761943417541) * 5.0) as int) = 1) THEN IC-2 WHEN (cast((rand(2762691268524896822) * 5.0) as int) = 2) THEN M1 WHEN (cast((rand(-8349312454092533537) * 5.0) as int) = 3) THEN M2 WHEN (cast((rand(4327064802130063657) * 5.0) as int) = 4) THEN IC-3 ELSE M3 END AS grade#557]\n",
      "      +- Project [id#537L, date#539, age#542, salary#546, CASE WHEN (cast((rand(-1048537541828757866) * 2.0) as int) = 0) THEN M ELSE F END AS gender#551]\n",
      "         +- Project [id#537L, date#539, age#542, (cast((rand(-2852223682338606353) * 100.0) as int) * 100) AS salary#546]\n",
      "            +- Project [id#537L, date#539, cast((rand(-24633094416071200) * 100.0) as int) AS age#542]\n",
      "               +- Project [id#537L, date_sub(2023-09-23, cast((rand(-4631883687744543562) * 365.0) as int)) AS date#539]\n",
      "                  +- Range (0, 10000000, step=1, splits=2)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_repartitioned.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ddc1d6cf-d898-414c-8e49-07f91160d8f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=true\n",
      "+- == Final Plan ==\n",
      "   ShuffleQueryStage 0\n",
      "   +- Exchange rangepartitioning(age#542 ASC NULLS FIRST, 5), REPARTITION_BY_NUM, [plan_id=1308]\n",
      "      +- *(1) Project [id#537L, date#539, age#542, salary#546, gender#551, CASE WHEN (cast((rand(7627123849445037294) * 5.0) as int) = 0) THEN IC WHEN (cast((rand(-3606855761943417541) * 5.0) as int) = 1) THEN IC-2 WHEN (cast((rand(2762691268524896822) * 5.0) as int) = 2) THEN M1 WHEN (cast((rand(-8349312454092533537) * 5.0) as int) = 3) THEN M2 WHEN (cast((rand(4327064802130063657) * 5.0) as int) = 4) THEN IC-3 ELSE M3 END AS grade#557]\n",
      "         +- *(1) Project [id#537L, date#539, age#542, salary#546, CASE WHEN (cast((rand(-1048537541828757866) * 2.0) as int) = 0) THEN M ELSE F END AS gender#551]\n",
      "            +- *(1) Project [id#537L, date#539, age#542, (cast((rand(-2852223682338606353) * 100.0) as int) * 100) AS salary#546]\n",
      "               +- *(1) Project [id#537L, date#539, cast((rand(-24633094416071200) * 100.0) as int) AS age#542]\n",
      "                  +- *(1) Project [id#537L, date_sub(2023-09-23, cast((rand(-4631883687744543562) * 365.0) as int)) AS date#539]\n",
      "                     +- *(1) Range (0, 10000000, step=1, splits=2)\n",
      "+- == Initial Plan ==\n",
      "   Exchange rangepartitioning(age#542 ASC NULLS FIRST, 5), REPARTITION_BY_NUM, [plan_id=1292]\n",
      "   +- Project [id#537L, date#539, age#542, salary#546, gender#551, CASE WHEN (cast((rand(7627123849445037294) * 5.0) as int) = 0) THEN IC WHEN (cast((rand(-3606855761943417541) * 5.0) as int) = 1) THEN IC-2 WHEN (cast((rand(2762691268524896822) * 5.0) as int) = 2) THEN M1 WHEN (cast((rand(-8349312454092533537) * 5.0) as int) = 3) THEN M2 WHEN (cast((rand(4327064802130063657) * 5.0) as int) = 4) THEN IC-3 ELSE M3 END AS grade#557]\n",
      "      +- Project [id#537L, date#539, age#542, salary#546, CASE WHEN (cast((rand(-1048537541828757866) * 2.0) as int) = 0) THEN M ELSE F END AS gender#551]\n",
      "         +- Project [id#537L, date#539, age#542, (cast((rand(-2852223682338606353) * 100.0) as int) * 100) AS salary#546]\n",
      "            +- Project [id#537L, date#539, cast((rand(-24633094416071200) * 100.0) as int) AS age#542]\n",
      "               +- Project [id#537L, date_sub(2023-09-23, cast((rand(-4631883687744543562) * 365.0) as int)) AS date#539]\n",
      "                  +- Range (0, 10000000, step=1, splits=2)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_repartitioned_by_range.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "526788c3-4a1d-4314-b2cc-b8f3c13683c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
